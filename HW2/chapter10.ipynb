{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d2c273-4825-4a30-9823-685fb14072f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80f2a9-572c-4b9f-bea4-a32a0b6a0e70",
   "metadata": {},
   "source": [
    "# CHAPTER 10 Codes\n",
    "## E10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74dd2b5d-bf7c-476b-97b4-b0710c2938a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADALINE_learning(input_Vectors, targets, alpha, initial_weights, initial_bias, verbose = True, epochs = -1):\n",
    "    \"\"\"\n",
    "    ADALINE learning method \n",
    "    note that in this network purelin transfer function (a.k.a activation function) is used\n",
    "\n",
    "    INPUTS:\n",
    "    ---------\n",
    "    input_Vectors:  numpy matrixes of inputs, each column is an input vector, meaning the inputs to the network\n",
    "    targets:  numpy array of targets, each target must be a scalar\n",
    "    alpha:  learning rate, must be a number between zero and one\n",
    "    initial_weights:  network weights\n",
    "    initial_bias:  network initial bias\n",
    "    verbose:  boolean variable, Enable learning logs or not\n",
    "    epochs:  how many iteration the network should iterate, default is -1 meaning it should be trained until convergence\n",
    "\n",
    "    OUTPUTS:\n",
    "    ---------\n",
    "    bias:  the bias that the network learned\n",
    "    weight: the weights that the network learned\n",
    "    Error:  each iteration (epoch) error is saved into a numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    ## save errors to return each epoch error to the user\n",
    "    Errors = []\n",
    "\n",
    "    assert alpha > 0 and alpha <= 1, \"Error, learning rate must be between 0 and 1\"\n",
    "\n",
    "    ## how many input vectors we have\n",
    "    inputs_count = input_Vectors.shape[1]\n",
    "\n",
    "    ## set the weights and bias to initial weights and bias\n",
    "    weights = np.copy(initial_weights)\n",
    "    bias = np.copy(initial_bias)\n",
    "\n",
    "    ## if the epochs wasn't set, train the network until convergence\n",
    "    ## else set the convergence to False\n",
    "    if epochs == -1:\n",
    "        convergence = True\n",
    "    else: \n",
    "        convergence = False\n",
    "\n",
    "    ## if epochs was set the convergence would be false but the (iter < epochs) will be true\n",
    "    ## else the convergence would be true\n",
    "    iter = 0\n",
    "    while (iter < epochs) or (convergence):\n",
    "        input_vector_number = iter % inputs_count\n",
    "        \n",
    "        ## check the actual output\n",
    "        a = weights.dot(input_Vectors[:, input_vector_number])\n",
    "        ## check the error        \n",
    "        error = targets[input_vector_number] - a\n",
    "        \n",
    "        Errors.append(error)\n",
    "        \n",
    "        ## update weights\n",
    "        updated_weights = weights + 2 * alpha * error * input_Vectors[:, input_vector_number].T\n",
    "        updated_bias = bias + 2 * alpha * error\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Actual output, iter: {iter:d}, input_vector: {input_vector_number: d}\\n' ,a )\n",
    "            print(\"old weights: \\n\", weights, \"\\nupdated weights: \", updated_weights)\n",
    "            print(\"old bias: \\n\", updated_bias, \"\\nupdated bias: \", updated_bias)\n",
    "\n",
    "        ## save for the next iteration\n",
    "        weights = updated_weights\n",
    "        bias = updated_bias\n",
    "        iter += 1\n",
    "\n",
    "    print(\"\\n\\nFinished\")\n",
    "    print(\"Updated last weight\\n\", weights)\n",
    "    print(\"Updated last bias\\n\", bias)\n",
    "    \n",
    "    return bias, weights, np.array(Errors).flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb45dee-2230-402a-b88d-e718fa4300f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output, iter: 0, input_vector:  0\n",
      " [[0]]\n",
      "old weights: \n",
      " [[0 0]] \n",
      "updated weights:  [[0.6 0.6]]\n",
      "old bias: \n",
      " [[0.6]] \n",
      "updated bias:  [[0.6]]\n",
      "Actual output, iter: 1, input_vector:  1\n",
      " [[-1.2]]\n",
      "old weights: \n",
      " [[0.6 0.6]] \n",
      "updated weights:  [[0.48 0.48]]\n",
      "old bias: \n",
      " [[0.72]] \n",
      "updated bias:  [[0.72]]\n",
      "Actual output, iter: 2, input_vector:  0\n",
      " [[0.96]]\n",
      "old weights: \n",
      " [[0.48 0.48]] \n",
      "updated weights:  [[0.504 0.504]]\n",
      "old bias: \n",
      " [[0.744]] \n",
      "updated bias:  [[0.744]]\n",
      "Actual output, iter: 3, input_vector:  1\n",
      " [[-1.008]]\n",
      "old weights: \n",
      " [[0.504 0.504]] \n",
      "updated weights:  [[0.4992 0.4992]]\n",
      "old bias: \n",
      " [[0.7488]] \n",
      "updated bias:  [[0.7488]]\n",
      "Actual output, iter: 4, input_vector:  0\n",
      " [[0.9984]]\n",
      "old weights: \n",
      " [[0.4992 0.4992]] \n",
      "updated weights:  [[0.50016 0.50016]]\n",
      "old bias: \n",
      " [[0.74976]] \n",
      "updated bias:  [[0.74976]]\n",
      "Actual output, iter: 5, input_vector:  1\n",
      " [[-1.00032]]\n",
      "old weights: \n",
      " [[0.50016 0.50016]] \n",
      "updated weights:  [[0.499968 0.499968]]\n",
      "old bias: \n",
      " [[0.749952]] \n",
      "updated bias:  [[0.749952]]\n",
      "Actual output, iter: 6, input_vector:  0\n",
      " [[0.999936]]\n",
      "old weights: \n",
      " [[0.499968 0.499968]] \n",
      "updated weights:  [[0.5000064 0.5000064]]\n",
      "old bias: \n",
      " [[0.7499904]] \n",
      "updated bias:  [[0.7499904]]\n",
      "Actual output, iter: 7, input_vector:  1\n",
      " [[-1.0000128]]\n",
      "old weights: \n",
      " [[0.5000064 0.5000064]] \n",
      "updated weights:  [[0.49999872 0.49999872]]\n",
      "old bias: \n",
      " [[0.74999808]] \n",
      "updated bias:  [[0.74999808]]\n",
      "Actual output, iter: 8, input_vector:  0\n",
      " [[0.99999744]]\n",
      "old weights: \n",
      " [[0.49999872 0.49999872]] \n",
      "updated weights:  [[0.50000026 0.50000026]]\n",
      "old bias: \n",
      " [[0.74999962]] \n",
      "updated bias:  [[0.74999962]]\n",
      "Actual output, iter: 9, input_vector:  1\n",
      " [[-1.00000051]]\n",
      "old weights: \n",
      " [[0.50000026 0.50000026]] \n",
      "updated weights:  [[0.49999995 0.49999995]]\n",
      "old bias: \n",
      " [[0.74999992]] \n",
      "updated bias:  [[0.74999992]]\n",
      "Actual output, iter: 10, input_vector:  0\n",
      " [[0.9999999]]\n",
      "old weights: \n",
      " [[0.49999995 0.49999995]] \n",
      "updated weights:  [[0.50000001 0.50000001]]\n",
      "old bias: \n",
      " [[0.74999998]] \n",
      "updated bias:  [[0.74999998]]\n",
      "Actual output, iter: 11, input_vector:  1\n",
      " [[-1.00000002]]\n",
      "old weights: \n",
      " [[0.50000001 0.50000001]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 12, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 13, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 14, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 15, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 16, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 17, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 18, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 19, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 20, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 21, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 22, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 23, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 24, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 25, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 26, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 27, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 28, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 29, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 30, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 31, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 32, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 33, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 34, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 35, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 36, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 37, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 38, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "Actual output, iter: 39, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.75]] \n",
      "updated bias:  [[0.75]]\n",
      "\n",
      "\n",
      "Finished\n",
      "Updated last weight\n",
      " [[0.5 0.5]]\n",
      "Updated last bias\n",
      " [[0.75]]\n"
     ]
    }
   ],
   "source": [
    "input_vectors = np.matrix('1 -1; 1 -1')\n",
    "targets = np.array([1, -1])\n",
    "## initialize weight and biases as zero\n",
    "weights = np.matrix('0 0')\n",
    "bias = 0\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "new_bias, new_weights, error = ADALINE_learning(input_vectors, \n",
    "                                        targets,\n",
    "                                        learning_rate,\n",
    "                                        weights, \n",
    "                                        bias, \n",
    "                                        verbose=True,\n",
    "                                        epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd714644-9b9a-4503-91a0-21c5e5a6a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See the error rate\n",
    "def plot_error(error, text_x ,text_y):\n",
    "    plt.plot(error)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('error')\n",
    "\n",
    "    ## plot a ```y = 0``` line\n",
    "    plt.plot(np.linspace(0, 40, 200), np.linspace(0, 0, 200))\n",
    "    plt.text(text_x, text_y, \"the orange line is the zero error\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d6ce8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(error, 20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97f1974-b46d-45ce-a398-f938e701aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output, iter: 0, input_vector:  0\n",
      " [[2]]\n",
      "old weights: \n",
      " [[1 1]] \n",
      "updated weights:  [[0.4 0.4]]\n",
      "old bias: \n",
      " [[0.4]] \n",
      "updated bias:  [[0.4]]\n",
      "Actual output, iter: 1, input_vector:  1\n",
      " [[-0.8]]\n",
      "old weights: \n",
      " [[0.4 0.4]] \n",
      "updated weights:  [[0.52 0.52]]\n",
      "old bias: \n",
      " [[0.28]] \n",
      "updated bias:  [[0.28]]\n",
      "Actual output, iter: 2, input_vector:  0\n",
      " [[1.04]]\n",
      "old weights: \n",
      " [[0.52 0.52]] \n",
      "updated weights:  [[0.496 0.496]]\n",
      "old bias: \n",
      " [[0.256]] \n",
      "updated bias:  [[0.256]]\n",
      "Actual output, iter: 3, input_vector:  1\n",
      " [[-0.992]]\n",
      "old weights: \n",
      " [[0.496 0.496]] \n",
      "updated weights:  [[0.5008 0.5008]]\n",
      "old bias: \n",
      " [[0.2512]] \n",
      "updated bias:  [[0.2512]]\n",
      "Actual output, iter: 4, input_vector:  0\n",
      " [[1.0016]]\n",
      "old weights: \n",
      " [[0.5008 0.5008]] \n",
      "updated weights:  [[0.49984 0.49984]]\n",
      "old bias: \n",
      " [[0.25024]] \n",
      "updated bias:  [[0.25024]]\n",
      "Actual output, iter: 5, input_vector:  1\n",
      " [[-0.99968]]\n",
      "old weights: \n",
      " [[0.49984 0.49984]] \n",
      "updated weights:  [[0.500032 0.500032]]\n",
      "old bias: \n",
      " [[0.250048]] \n",
      "updated bias:  [[0.250048]]\n",
      "Actual output, iter: 6, input_vector:  0\n",
      " [[1.000064]]\n",
      "old weights: \n",
      " [[0.500032 0.500032]] \n",
      "updated weights:  [[0.4999936 0.4999936]]\n",
      "old bias: \n",
      " [[0.2500096]] \n",
      "updated bias:  [[0.2500096]]\n",
      "Actual output, iter: 7, input_vector:  1\n",
      " [[-0.9999872]]\n",
      "old weights: \n",
      " [[0.4999936 0.4999936]] \n",
      "updated weights:  [[0.50000128 0.50000128]]\n",
      "old bias: \n",
      " [[0.25000192]] \n",
      "updated bias:  [[0.25000192]]\n",
      "Actual output, iter: 8, input_vector:  0\n",
      " [[1.00000256]]\n",
      "old weights: \n",
      " [[0.50000128 0.50000128]] \n",
      "updated weights:  [[0.49999974 0.49999974]]\n",
      "old bias: \n",
      " [[0.25000038]] \n",
      "updated bias:  [[0.25000038]]\n",
      "Actual output, iter: 9, input_vector:  1\n",
      " [[-0.99999949]]\n",
      "old weights: \n",
      " [[0.49999974 0.49999974]] \n",
      "updated weights:  [[0.50000005 0.50000005]]\n",
      "old bias: \n",
      " [[0.25000008]] \n",
      "updated bias:  [[0.25000008]]\n",
      "Actual output, iter: 10, input_vector:  0\n",
      " [[1.0000001]]\n",
      "old weights: \n",
      " [[0.50000005 0.50000005]] \n",
      "updated weights:  [[0.49999999 0.49999999]]\n",
      "old bias: \n",
      " [[0.25000002]] \n",
      "updated bias:  [[0.25000002]]\n",
      "Actual output, iter: 11, input_vector:  1\n",
      " [[-0.99999998]]\n",
      "old weights: \n",
      " [[0.49999999 0.49999999]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 12, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 13, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 14, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 15, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 16, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 17, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 18, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 19, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 20, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 21, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 22, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 23, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 24, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 25, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 26, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 27, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 28, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 29, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 30, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 31, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 32, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 33, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 34, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 35, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 36, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 37, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 38, input_vector:  0\n",
      " [[1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "Actual output, iter: 39, input_vector:  1\n",
      " [[-1.]]\n",
      "old weights: \n",
      " [[0.5 0.5]] \n",
      "updated weights:  [[0.5 0.5]]\n",
      "old bias: \n",
      " [[0.25]] \n",
      "updated bias:  [[0.25]]\n",
      "\n",
      "\n",
      "Finished\n",
      "Updated last weight\n",
      " [[0.5 0.5]]\n",
      "Updated last bias\n",
      " [[0.25]]\n"
     ]
    }
   ],
   "source": [
    "input_vectors = np.matrix('1 -1; 1 -1')\n",
    "targets = np.array([1, -1])\n",
    "## initialize weight and biases as zero\n",
    "weights = np.matrix('1 1')\n",
    "bias = 1\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "new_bias_1, new_weights_1, error = ADALINE_learning(input_vectors, \n",
    "                                        targets,\n",
    "                                        learning_rate,\n",
    "                                        weights, \n",
    "                                        bias, \n",
    "                                        verbose=True,\n",
    "                                        epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed740e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(error, 20, -0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0051edfa-6362-4441-ae3e-e140e895a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial wieghts and biases as zeros\n",
      "Learned Weights: \n",
      " [[0.5 0.5]]\n",
      "Learned biases: \n",
      " [[0.75]]\n",
      "\n",
      "\n",
      "Initial wieghts and biases as ones\n",
      "Learned Weights: \n",
      " [[0.5 0.5]]\n",
      "Learned biases: \n",
      " [[0.25]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial wieghts and biases as zeros\")\n",
    "print(\"Learned Weights: \\n\", new_weights)\n",
    "print(\"Learned biases: \\n\", new_bias)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Initial wieghts and biases as ones\")\n",
    "print(\"Learned Weights: \\n\", new_weights_1)\n",
    "print(\"Learned biases: \\n\", new_bias_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411d9e6-a6bc-4ea2-982a-8960434a03d3",
   "metadata": {},
   "source": [
    "## E10.14\n",
    "data for 1 and 2 and 4 in the grids would be like this grids below\n",
    "\n",
    "### one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05467a-1f4a-4464-8ae9-e616eebdfc42",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>one</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "</table>\n",
    "Second shifted one\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>one</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018aad6-3076-41a7-8848-d795cd68f9f6",
   "metadata": {},
   "source": [
    "### two\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>two</td>\n",
    "        <td>two</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<b>Second shifted two is</b>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>two</td>\n",
    "        <td>two</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1d2fc-f540-4505-9349-5001d22a725a",
   "metadata": {},
   "source": [
    "### four\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>four</td>\n",
    "        <td>four</td>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<b>second shifted four is </b>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>four</td>\n",
    "        <td>four</td>\n",
    "        <td>four</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>~</td>\n",
    "        <td>~</td>\n",
    "        <td>four</td>\n",
    "        <td>~</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289965b0-2290-41ff-ba0c-1de11db7c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output, iter: 0, input_vector:  0\n",
      " [[0]]\n",
      "old weights: \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]] \n",
      "updated weights:  [[ 0.6  0.6 -0.6 -0.6 -0.6  0.6 -0.6 -0.6 -0.6  0.6 -0.6 -0.6 -0.6  0.6\n",
      "  -0.6 -0.6]]\n",
      "old bias: \n",
      " [[1.6]] \n",
      "updated bias:  [[1.6]]\n",
      "Actual output, iter: 1, input_vector:  1\n",
      " [[0.]]\n",
      "old weights: \n",
      " [[ 0.6  0.6 -0.6 -0.6 -0.6  0.6 -0.6 -0.6 -0.6  0.6 -0.6 -0.6 -0.6  0.6\n",
      "  -0.6 -0.6]] \n",
      "updated weights:  [[ 0.   1.2  0.  -1.2 -1.2  0.   0.  -1.2 -1.2  0.   0.  -1.2 -1.2  0.\n",
      "   0.  -1.2]]\n",
      "old bias: \n",
      " [[2.2]] \n",
      "updated bias:  [[2.2]]\n",
      "Actual output, iter: 2, input_vector:  2\n",
      " [[4.8]]\n",
      "old weights: \n",
      " [[ 0.   1.2  0.  -1.2 -1.2  0.   0.  -1.2 -1.2  0.   0.  -1.2 -1.2  0.\n",
      "   0.  -1.2]] \n",
      "updated weights:  [[ 1.68 -0.48  1.68  0.48 -2.88  1.68 -1.68  0.48  0.48 -1.68  1.68  0.48\n",
      "   0.48 -1.68 -1.68 -2.88]]\n",
      "old bias: \n",
      " [[0.52]] \n",
      "updated bias:  [[0.52]]\n",
      "Actual output, iter: 3, input_vector:  3\n",
      " [[5.76]]\n",
      "old weights: \n",
      " [[ 1.68 -0.48  1.68  0.48 -2.88  1.68 -1.68  0.48  0.48 -1.68  1.68  0.48\n",
      "   0.48 -1.68 -1.68 -2.88]] \n",
      "updated weights:  [[ 3.936  1.776 -0.576  2.736 -0.624 -0.576  0.576 -1.776  2.736  0.576\n",
      "  -0.576  2.736  2.736  0.576 -3.936 -5.136]]\n",
      "old bias: \n",
      " [[-1.736]] \n",
      "updated bias:  [[-1.736]]\n",
      "Actual output, iter: 4, input_vector:  4\n",
      " [[3.744]]\n",
      "old weights: \n",
      " [[ 3.936  1.776 -0.576  2.736 -0.624 -0.576  0.576 -1.776  2.736  0.576\n",
      "  -0.576  2.736  2.736  0.576 -3.936 -5.136]] \n",
      "updated weights:  [[ 3.7824  1.9296 -0.7296  2.5824 -0.4704 -0.7296  0.4224 -1.9296  2.8896\n",
      "   0.7296 -0.4224  2.5824  2.5824  0.7296 -4.0896 -5.2896]]\n",
      "old bias: \n",
      " [[-1.5824]] \n",
      "updated bias:  [[-1.5824]]\n",
      "Actual output, iter: 5, input_vector:  5\n",
      " [[-9.888]]\n",
      "old weights: \n",
      " [[ 3.7824  1.9296 -0.7296  2.5824 -0.4704 -0.7296  0.4224 -1.9296  2.8896\n",
      "   0.7296 -0.4224  2.5824  2.5824  0.7296 -4.0896 -5.2896]] \n",
      "updated weights:  [[ -4.5504  -6.4032   7.6032  -5.7504  -8.8032   7.6032  -7.9104 -10.2624\n",
      "   -5.4432   9.0624   7.9104  10.9152  -5.7504  -7.6032   4.2432 -13.6224]]\n",
      "old bias: \n",
      " [[6.7504]] \n",
      "updated bias:  [[6.7504]]\n",
      "Actual output, iter: 6, input_vector:  0\n",
      " [[24.9792]]\n",
      "old weights: \n",
      " [[ -4.5504  -6.4032   7.6032  -5.7504  -8.8032   7.6032  -7.9104 -10.2624\n",
      "   -5.4432   9.0624   7.9104  10.9152  -5.7504  -7.6032   4.2432 -13.6224]] \n",
      "updated weights:  [[-18.93792 -20.79072  21.99072   8.63712   5.58432  -6.78432   6.47712\n",
      "    4.12512   8.94432  -5.32512  22.29792  25.30272   8.63712 -21.99072\n",
      "   18.63072   0.76512]]\n",
      "old bias: \n",
      " [[-7.63712]] \n",
      "updated bias:  [[-7.63712]]\n",
      "Actual output, iter: 7, input_vector:  1\n",
      " [[39.648]]\n",
      "old weights: \n",
      " [[-18.93792 -20.79072  21.99072   8.63712   5.58432  -6.78432   6.47712\n",
      "    4.12512   8.94432  -5.32512  22.29792  25.30272   8.63712 -21.99072\n",
      "   18.63072   0.76512]] \n",
      "updated weights:  [[  4.25088 -43.97952  -1.19808  31.82592  28.77312  16.40448 -16.71168\n",
      "   27.31392  32.13312  17.86368  -0.89088  48.49152  31.82592   1.19808\n",
      "   -4.55808  23.95392]]\n",
      "old bias: \n",
      " [[-30.82592]] \n",
      "updated bias:  [[-30.82592]]\n",
      "Actual output, iter: 8, input_vector:  2\n",
      " [[-183.61728]]\n",
      "old weights: \n",
      " [[  4.25088 -43.97952  -1.19808  31.82592  28.77312  16.40448 -16.71168\n",
      "   27.31392  32.13312  17.86368  -0.89088  48.49152  31.82592   1.19808\n",
      "   -4.55808  23.95392]] \n",
      "updated weights:  [[-107.119488   67.390848 -112.568448  -79.544448  140.143488  -94.965888\n",
      "    94.658688  -84.056448  -79.237248  129.234048 -112.261248  -62.878848\n",
      "   -79.544448  112.568448  106.812288  135.324288]]\n",
      "old bias: \n",
      " [[80.544448]] \n",
      "updated bias:  [[80.544448]]\n",
      "Actual output, iter: 9, input_vector:  3\n",
      " [[-297.386496]]\n",
      "old weights: \n",
      " [[-107.119488   67.390848 -112.568448  -79.544448  140.143488  -94.965888\n",
      "    94.658688  -84.056448  -79.237248  129.234048 -112.261248  -62.878848\n",
      "   -79.544448  112.568448  106.812288  135.324288]] \n",
      "updated weights:  [[-286.7513856 -112.2410496   67.0634496 -259.1763456  -39.4884096\n",
      "    84.6660096  -84.9732096   95.5754496 -258.8691456  -50.3978496\n",
      "    67.3706496 -242.5107456 -259.1763456  -67.0634496  286.4441856\n",
      "   314.9561856]]\n",
      "old bias: \n",
      " [[260.1763456]] \n",
      "updated bias:  [[260.1763456]]\n",
      "Actual output, iter: 10, input_vector:  4\n",
      " [[-176.8065024]]\n",
      "old weights: \n",
      " [[-286.7513856 -112.2410496   67.0634496 -259.1763456  -39.4884096\n",
      "    84.6660096  -84.9732096   95.5754496 -258.8691456  -50.3978496\n",
      "    67.3706496 -242.5107456 -259.1763456  -67.0634496  286.4441856\n",
      "   314.9561856]] \n",
      "updated weights:  [[-395.23528704   -3.75714816  -41.42045184 -367.66024704   68.99549184\n",
      "   -23.81789184 -193.45711104  -12.90845184 -150.38524416   58.08605184\n",
      "   175.85455104 -350.99464704 -367.66024704   41.42045184  177.96028416\n",
      "   206.47228416]]\n",
      "old bias: \n",
      " [[368.66024704]] \n",
      "updated bias:  [[368.66024704]]\n",
      "Actual output, iter: 11, input_vector:  5\n",
      " [[1169.8434048]]\n",
      "old weights: \n",
      " [[-395.23528704   -3.75714816  -41.42045184 -367.66024704   68.99549184\n",
      "   -23.81789184 -193.45711104  -12.90845184 -150.38524416   58.08605184\n",
      "   175.85455104 -350.99464704 -367.66024704   41.42045184  177.96028416\n",
      "   206.47228416]] \n",
      "updated weights:  [[  304.27075584   695.74889472  -740.92649472   331.84579584\n",
      "    768.50153472  -723.32393472   506.04893184   686.59759104\n",
      "    549.12079872  -641.41999104  -523.65149184 -1050.50068992\n",
      "    331.84579584   740.92649472  -521.54575872   905.97832704]]\n",
      "old bias: \n",
      " [[-330.84579584]] \n",
      "updated bias:  [[-330.84579584]]\n",
      "Actual output, iter: 12, input_vector:  0\n",
      " [[-867.11212032]]\n",
      "old weights: \n",
      " [[  304.27075584   695.74889472  -740.92649472   331.84579584\n",
      "    768.50153472  -723.32393472   506.04893184   686.59759104\n",
      "    549.12079872  -641.41999104  -523.65149184 -1050.50068992\n",
      "    331.84579584   740.92649472  -521.54575872   905.97832704]] \n",
      "updated weights:  [[  825.13802803  1216.61616691 -1261.79376691  -189.02147635\n",
      "    247.63426253  -202.45666253   -14.81834035   165.73031885\n",
      "     28.25352653  -120.55271885 -1044.51876403 -1571.36796211\n",
      "   -189.02147635  1261.79376691 -1042.41303091   385.11105485]]\n",
      "old bias: \n",
      " [[190.02147635]] \n",
      "updated bias:  [[190.02147635]]\n",
      "Actual output, iter: 13, input_vector:  1\n",
      " [[-2788.1683968]]\n",
      "old weights: \n",
      " [[  825.13802803  1216.61616691 -1261.79376691  -189.02147635\n",
      "    247.63426253  -202.45666253   -14.81834035   165.73031885\n",
      "     28.25352653  -120.55271885 -1044.51876403 -1571.36796211\n",
      "   -189.02147635  1261.79376691 -1042.41303091   385.11105485]] \n",
      "updated weights:  [[ -848.36301005  2890.11720499   411.70727117 -1862.52251443\n",
      "  -1425.86677555 -1875.95770061  1658.68269773 -1507.77071923\n",
      "  -1645.24751155 -1794.05375693   628.98227405 -3244.86900019\n",
      "  -1862.52251443  -411.70727117   631.08800717 -1288.38998323]]\n",
      "old bias: \n",
      " [[1863.52251443]] \n",
      "updated bias:  [[1863.52251443]]\n",
      "Actual output, iter: 14, input_vector:  2\n",
      " [[12066.43354829]]\n",
      "old weights: \n",
      " [[ -848.36301005  2890.11720499   411.70727117 -1862.52251443\n",
      "  -1425.86677555 -1875.95770061  1658.68269773 -1507.77071923\n",
      "  -1645.24751155 -1794.05375693   628.98227405 -3244.86900019\n",
      "  -1862.52251443  -411.70727117   631.08800717 -1288.38998323]] \n",
      "updated weights:  [[ 6390.29711892 -4348.54292398  7650.36740014  5376.13761454\n",
      "  -8664.52690452  5362.70242836 -5579.97743124  5730.88940974\n",
      "   5593.41261742 -9032.7138859   7867.64240302  3993.79112878\n",
      "   5376.13761454 -7650.36740014 -6607.5721218  -8527.0501122 ]]\n",
      "old bias: \n",
      " [[-5375.13761454]] \n",
      "updated bias:  [[-5375.13761454]]\n",
      "Actual output, iter: 15, input_vector:  3\n",
      " [[20023.33185884]]\n",
      "old weights: \n",
      " [[ 6390.29711892 -4348.54292398  7650.36740014  5376.13761454\n",
      "  -8664.52690452  5362.70242836 -5579.97743124  5730.88940974\n",
      "   5593.41261742 -9032.7138859   7867.64240302  3993.79112878\n",
      "   5376.13761454 -7650.36740014 -6607.5721218  -8527.0501122 ]] \n",
      "updated weights:  [[ 18403.09623423   7664.25619132  -4362.43171516  17388.93672985\n",
      "    3348.27221078  -6650.09668694   6432.82168406  -6281.90970556\n",
      "   17606.21173273   2980.0852294   -4145.15671228  16006.59024409\n",
      "   17388.93672985   4362.43171516 -18620.37123711 -20539.84922751]]\n",
      "old bias: \n",
      " [[-17387.93672985]] \n",
      "updated bias:  [[-17387.93672985]]\n",
      "Actual output, iter: 16, input_vector:  4\n",
      " [[12650.37731734]]\n",
      "old weights: \n",
      " [[ 18403.09623423   7664.25619132  -4362.43171516  17388.93672985\n",
      "    3348.27221078  -6650.09668694   6432.82168406  -6281.90970556\n",
      "   17606.21173273   2980.0852294   -4145.15671228  16006.59024409\n",
      "   17388.93672985   4362.43171516 -18620.37123711 -20539.84922751]] \n",
      "updated weights:  [[ 25990.92262463     76.42980092   3225.39467524  24976.76312025\n",
      "   -4239.55417962    937.72970346  14020.64807446   1305.91668484\n",
      "   10018.38534232  -4607.741161   -11732.98310269  23594.41663449\n",
      "   24976.76312025  -3225.39467524 -11032.54484671 -12952.02283711]]\n",
      "old bias: \n",
      " [[-24975.76312025]] \n",
      "updated bias:  [[-24975.76312025]]\n",
      "Actual output, iter: 17, input_vector:  5\n",
      " [[-80564.58517291]]\n",
      "old weights: \n",
      " [[ 25990.92262463     76.42980092   3225.39467524  24976.76312025\n",
      "   -4239.55417962    937.72970346  14020.64807446   1305.91668484\n",
      "   10018.38534232  -4607.741161   -11732.98310269  23594.41663449\n",
      "   24976.76312025  -3225.39467524 -11032.54484671 -12952.02283711]] \n",
      "updated weights:  [[-22350.22847912 -48264.72130282  51566.54577898 -23364.3879835\n",
      "  -52580.70528337  49278.88080721 -34320.50302928 -47035.23441891\n",
      "  -38322.76576142  43733.40994275  36608.16800106  71935.56773823\n",
      "  -23364.3879835  -51566.54577898  37308.60625704 -61293.17394085]]\n",
      "old bias: \n",
      " [[23365.3879835]] \n",
      "updated bias:  [[23365.3879835]]\n",
      "Actual output, iter: 18, input_vector:  0\n",
      " [[53693.06581456]]\n",
      "old weights: \n",
      " [[-22350.22847912 -48264.72130282  51566.54577898 -23364.3879835\n",
      "  -52580.70528337  49278.88080721 -34320.50302928 -47035.23441891\n",
      "  -38322.76576142  43733.40994275  36608.16800106  71935.56773823\n",
      "  -23364.3879835  -51566.54577898  37308.60625704 -61293.17394085]] \n",
      "updated weights:  [[-54565.46796785 -80479.96079156  83781.78526772   8850.85150523\n",
      "  -20365.46579463  17063.64131847  -2105.26354055 -14819.99493018\n",
      "   -6107.52627269  11518.17045402  68823.40748979 104150.80722697\n",
      "    8850.85150523 -83781.78526772  69523.84574577 -29077.93445212]]\n",
      "old bias: \n",
      " [[-8849.85150523]] \n",
      "updated bias:  [[-8849.85150523]]\n",
      "Actual output, iter: 19, input_vector:  1\n",
      " [[197827.66684643]]\n",
      "old weights: \n",
      " [[-54565.46796785 -80479.96079156  83781.78526772   8850.85150523\n",
      "  -20365.46579463  17063.64131847  -2105.26354055 -14819.99493018\n",
      "   -6107.52627269  11518.17045402  68823.40748979 104150.80722697\n",
      "    8850.85150523 -83781.78526772  69523.84574577 -29077.93445212]] \n",
      "updated weights:  [[  64130.53214001 -199175.96089942  -34914.21484014  127546.85161309\n",
      "    98330.53431323  135759.64142633 -120801.26364841  103876.00517768\n",
      "   112588.47383517  130214.17056188  -49872.59261807  222846.80733483\n",
      "   127546.85161309   34914.21484014  -49172.15436209   89618.06565574]]\n",
      "old bias: \n",
      " [[-127545.85161309]] \n",
      "updated bias:  [[-127545.85161309]]\n",
      "Actual output, iter: 20, input_vector:  2\n",
      " [[-825580.74922094]]\n",
      "old weights: \n",
      " [[  64130.53214001 -199175.96089942  -34914.21484014  127546.85161309\n",
      "    98330.53431323  135759.64142633 -120801.26364841  103876.00517768\n",
      "   112588.47383517  130214.17056188  -49872.59261807  222846.80733483\n",
      "   127546.85161309   34914.21484014  -49172.15436209   89618.06565574]] \n",
      "updated weights:  [[-431219.11739255  296173.68863315 -530263.86437271 -367802.79791947\n",
      "   593680.18384579 -359590.00810623  374548.38588415 -391473.64435488\n",
      "  -382761.17569739  625563.82009444 -545222.24215063 -272502.84219774\n",
      "  -367802.79791947  530263.86437271  446177.49517048  584967.7151883 ]]\n",
      "old bias: \n",
      " [[367803.79791947]] \n",
      "updated bias:  [[367803.79791947]]\n",
      "Actual output, iter: 21, input_vector:  3\n",
      " [[-1393545.76032929]]\n",
      "old weights: \n",
      " [[-431219.11739255  296173.68863315 -530263.86437271 -367802.79791947\n",
      "   593680.18384579 -359590.00810623  374548.38588415 -391473.64435488\n",
      "  -382761.17569739  625563.82009444 -545222.24215063 -272502.84219774\n",
      "  -367802.79791947  530263.86437271  446177.49517048  584967.7151883 ]] \n",
      "updated weights:  [[-1267347.77359013  -539954.96756442   305864.79182486 -1203931.45411704\n",
      "   -242448.47235178   476538.64809134  -461580.27031342   444655.01184269\n",
      "  -1218889.83189496  -210564.83610313   290906.41404694 -1108631.49839531\n",
      "  -1203931.45411704  -305864.79182486  1282306.15136805  1421096.37138588]]\n",
      "old bias: \n",
      " [[1203932.45411704]] \n",
      "updated bias:  [[1203932.45411704]]\n",
      "Actual output, iter: 22, input_vector:  4\n",
      " [[-911855.0096721]]\n",
      "old weights: \n",
      " [[-1267347.77359013  -539954.96756442   305864.79182486 -1203931.45411704\n",
      "   -242448.47235178   476538.64809134  -461580.27031342   444655.01184269\n",
      "  -1218889.83189496  -210564.83610313   290906.41404694 -1108631.49839531\n",
      "  -1203931.45411704  -305864.79182486  1282306.15136805  1421096.37138588]] \n",
      "updated weights:  [[-1814463.17939339     7160.43823884  -241250.6139784  -1751046.8599203\n",
      "    304666.93345148   -70576.75771192 -1008695.67611668  -102460.39396057\n",
      "   -671774.4260917    336550.56970013   838021.8198502  -1655746.90419857\n",
      "  -1751046.8599203    241250.6139784    735190.74556478   873980.96558261]]\n",
      "old bias: \n",
      " [[1751047.8599203]] \n",
      "updated bias:  [[1751047.8599203]]\n",
      "Actual output, iter: 23, input_vector:  5\n",
      " [[5614617.30337784]]\n",
      "old weights: \n",
      " [[-1814463.17939339     7160.43823884  -241250.6139784  -1751046.8599203\n",
      "    304666.93345148   -70576.75771192 -1008695.67611668  -102460.39396057\n",
      "   -671774.4260917    336550.56970013   838021.8198502  -1655746.90419857\n",
      "  -1751046.8599203    241250.6139784    735190.74556478   873980.96558261]] \n",
      "updated weights:  [[ 1554304.80263332  3375928.42026554 -3610018.5960051   1617721.1221064\n",
      "   3673434.91547819 -3439344.73973863  2360072.30591003  3266307.58806614\n",
      "   2696993.55593501 -3032217.41232658 -2530746.1621765  -5024514.88622528\n",
      "   1617721.1221064   3610018.5960051  -2633577.23646192  4242748.94760932]]\n",
      "old bias: \n",
      " [[-1617720.1221064]] \n",
      "updated bias:  [[-1617720.1221064]]\n",
      "Actual output, iter: 24, input_vector:  0\n",
      " [[-3607453.00950391]]\n",
      "old weights: \n",
      " [[ 1554304.80263332  3375928.42026554 -3610018.5960051   1617721.1221064\n",
      "   3673434.91547819 -3439344.73973863  2360072.30591003  3266307.58806614\n",
      "   2696993.55593501 -3032217.41232658 -2530746.1621765  -5024514.88622528\n",
      "   1617721.1221064   3610018.5960051  -2633577.23646192  4242748.94760932]] \n",
      "updated weights:  [[ 3718777.20833566  5540400.82596789 -5774491.00170745  -546751.28359594\n",
      "   1508962.50977584 -1274872.33403628   195599.90020768  1101835.18236379\n",
      "    532521.15023266  -867745.00662423 -4695218.56787885 -7188987.29192762\n",
      "   -546751.28359594  5774491.00170745 -4798049.64216427  2078276.54190697]]\n",
      "old bias: \n",
      " [[546752.28359594]] \n",
      "updated bias:  [[546752.28359594]]\n",
      "Actual output, iter: 25, input_vector:  1\n",
      " [[-13821514.88011735]]\n",
      "old weights: \n",
      " [[ 3718777.20833566  5540400.82596789 -5774491.00170745  -546751.28359594\n",
      "   1508962.50977584 -1274872.33403628   195599.90020768  1101835.18236379\n",
      "    532521.15023266  -867745.00662423 -4695218.56787885 -7188987.29192762\n",
      "   -546751.28359594  5774491.00170745 -4798049.64216427  2078276.54190697]] \n",
      "updated weights:  [[ -4574132.31973475  13833310.3540383    2518418.52636296\n",
      "   -8839660.81166635  -6783947.01829457  -9567781.86210669\n",
      "    8488509.42827809  -7191074.34570662  -7760388.37783775\n",
      "   -9160654.53469464   3597690.96019156 -15481896.81999803\n",
      "   -8839660.81166635  -2518418.52636296   3494859.88590614\n",
      "   -6214632.98616344]]\n",
      "old bias: \n",
      " [[8839661.81166635]] \n",
      "updated bias:  [[8839661.81166635]]\n",
      "Actual output, iter: 26, input_vector:  2\n",
      " [[57277512.46486895]]\n",
      "old weights: \n",
      " [[ -4574132.31973475  13833310.3540383    2518418.52636296\n",
      "   -8839660.81166635  -6783947.01829457  -9567781.86210669\n",
      "    8488509.42827809  -7191074.34570662  -7760388.37783775\n",
      "   -9160654.53469464   3597690.96019156 -15481896.81999803\n",
      "   -8839660.81166635  -2518418.52636296   3494859.88590614\n",
      "   -6214632.98616344]] \n",
      "updated weights:  [[ 29792373.95918662 -20533195.92488307  36884924.80528432\n",
      "   25526845.46725501 -41150453.29721593  24798724.41681467\n",
      "  -25877996.85064328  27175431.93321475  26606117.90108362\n",
      "  -43527160.81361601  37964197.23911293  18884609.45892333\n",
      "   25526845.46725501 -36884924.80528432 -30871646.39301522\n",
      "  -40581139.2650848 ]]\n",
      "old bias: \n",
      " [[-25526844.46725501]] \n",
      "updated bias:  [[-25526844.46725501]]\n",
      "Actual output, iter: 27, input_vector:  3\n",
      " [[97007432.17426565]]\n",
      "old weights: \n",
      " [[ 29792373.95918662 -20533195.92488307  36884924.80528432\n",
      "   25526845.46725501 -41150453.29721593  24798724.41681467\n",
      "  -25877996.85064328  27175431.93321475  26606117.90108362\n",
      "  -43527160.81361601  37964197.23911293  18884609.45892333\n",
      "   25526845.46725501 -36884924.80528432 -30871646.39301522\n",
      "  -40581139.2650848 ]] \n",
      "updated weights:  [[ 87996832.063746    37671262.17967632 -21319533.29927507\n",
      "   83731303.5718144   17054004.80734346 -33405733.68774472\n",
      "   32326461.25391611 -31029026.17134465  84810576.00564301\n",
      "   14677297.29094338 -20240260.86544646  77089067.56348273\n",
      "   83731303.5718144   21319533.29927507 -89076104.49757461\n",
      "  -98785597.3696442 ]]\n",
      "old bias: \n",
      " [[-83731302.5718144]] \n",
      "updated bias:  [[-83731302.5718144]]\n",
      "Actual output, iter: 28, input_vector:  4\n",
      " [[64033439.71824436]]\n",
      "old weights: \n",
      " [[ 87996832.063746    37671262.17967632 -21319533.29927507\n",
      "   83731303.5718144   17054004.80734346 -33405733.68774472\n",
      "   32326461.25391611 -31029026.17134465  84810576.00564301\n",
      "   14677297.29094338 -20240260.86544646  77089067.56348273\n",
      "   83731303.5718144   21319533.29927507 -89076104.49757461\n",
      "  -98785597.3696442 ]] \n",
      "updated weights:  [[ 1.26416893e+08 -7.48799251e+05  1.71005281e+07  1.22151365e+08\n",
      "  -2.13660566e+07  5.01432774e+06  7.07465227e+07  7.39103526e+06\n",
      "   4.63905146e+07 -2.37427641e+07 -5.86603223e+07  1.15509129e+08\n",
      "   1.22151365e+08 -1.71005281e+07 -5.06560431e+07 -6.03655359e+07]]\n",
      "old bias: \n",
      " [[-1.22151364e+08]] \n",
      "updated bias:  [[-1.22151364e+08]]\n",
      "Actual output, iter: 29, input_vector:  5\n",
      " [[-3.91101921e+08]]\n",
      "old weights: \n",
      " [[ 1.26416893e+08 -7.48799251e+05  1.71005281e+07  1.22151365e+08\n",
      "  -2.13660566e+07  5.01432774e+06  7.07465227e+07  7.39103526e+06\n",
      "   4.63905146e+07 -2.37427641e+07 -5.86603223e+07  1.15509129e+08\n",
      "   1.22151365e+08 -1.71005281e+07 -5.06560431e+07 -6.03655359e+07]] \n",
      "updated weights:  [[-1.08244261e+08 -2.35409954e+08  2.51761683e+08 -1.12509790e+08\n",
      "  -2.56027211e+08  2.39675483e+08 -1.63914632e+08 -2.27270120e+08\n",
      "  -1.88270640e+08  2.10918391e+08  1.76000833e+08  3.50170284e+08\n",
      "  -1.12509790e+08 -2.51761683e+08  1.84005112e+08 -2.95026691e+08]]\n",
      "old bias: \n",
      " [[1.12509791e+08]] \n",
      "updated bias:  [[1.12509791e+08]]\n",
      "Actual output, iter: 30, input_vector:  0\n",
      " [[2.48768938e+08]]\n",
      "old weights: \n",
      " [[-1.08244261e+08 -2.35409954e+08  2.51761683e+08 -1.12509790e+08\n",
      "  -2.56027211e+08  2.39675483e+08 -1.63914632e+08 -2.27270120e+08\n",
      "  -1.88270640e+08  2.10918391e+08  1.76000833e+08  3.50170284e+08\n",
      "  -1.12509790e+08 -2.51761683e+08  1.84005112e+08 -2.95026691e+08]] \n",
      "updated weights:  [[-2.57505623e+08 -3.84671316e+08  4.01023045e+08  3.67515722e+07\n",
      "  -1.06765849e+08  9.04141206e+07 -1.46532702e+07 -7.80087576e+07\n",
      "  -3.90092783e+07  6.16570287e+07  3.25262195e+08  4.99431646e+08\n",
      "   3.67515722e+07 -4.01023045e+08  3.33266474e+08 -1.45765329e+08]]\n",
      "old bias: \n",
      " [[-36751571.16139591]] \n",
      "updated bias:  [[-36751571.16139591]]\n",
      "Actual output, iter: 31, input_vector:  1\n",
      " [[9.6329907e+08]]\n",
      "old weights: \n",
      " [[-2.57505623e+08 -3.84671316e+08  4.01023045e+08  3.67515722e+07\n",
      "  -1.06765849e+08  9.04141206e+07 -1.46532702e+07 -7.80087576e+07\n",
      "  -3.90092783e+07  6.16570287e+07  3.25262195e+08  4.99431646e+08\n",
      "   3.67515722e+07 -4.01023045e+08  3.33266474e+08 -1.45765329e+08]] \n",
      "updated weights:  [[ 3.20473818e+08 -9.62650757e+08 -1.76956396e+08  6.14731014e+08\n",
      "   4.71213592e+08  6.68393562e+08 -5.92632712e+08  4.99970684e+08\n",
      "   5.38970163e+08  6.39636470e+08 -2.52717247e+08  1.07741109e+09\n",
      "   6.14731014e+08  1.76956396e+08 -2.44712968e+08  4.32214113e+08]]\n",
      "old bias: \n",
      " [[-6.14731013e+08]] \n",
      "updated bias:  [[-6.14731013e+08]]\n",
      "Actual output, iter: 32, input_vector:  2\n",
      " [[-3.98498356e+09]]\n",
      "old weights: \n",
      " [[ 3.20473818e+08 -9.62650757e+08 -1.76956396e+08  6.14731014e+08\n",
      "   4.71213592e+08  6.68393562e+08 -5.92632712e+08  4.99970684e+08\n",
      "   5.38970163e+08  6.39636470e+08 -2.52717247e+08  1.07741109e+09\n",
      "   6.14731014e+08  1.76956396e+08 -2.44712968e+08  4.32214113e+08]] \n",
      "updated weights:  [[-2.07051632e+09  1.42833938e+09 -2.56794654e+09 -1.77625913e+09\n",
      "   2.86220373e+09 -1.72259658e+09  1.79835743e+09 -1.89101946e+09\n",
      "  -1.85201998e+09  3.03062661e+09 -2.64370739e+09 -1.31357905e+09\n",
      "  -1.77625913e+09  2.56794654e+09  2.14627717e+09  2.82320425e+09]]\n",
      "old bias: \n",
      " [[1.77625913e+09]] \n",
      "updated bias:  [[1.77625913e+09]]\n",
      "Actual output, iter: 33, input_vector:  3\n",
      " [[-6.75462862e+09]]\n",
      "old weights: \n",
      " [[-2.07051632e+09  1.42833938e+09 -2.56794654e+09 -1.77625913e+09\n",
      "   2.86220373e+09 -1.72259658e+09  1.79835743e+09 -1.89101946e+09\n",
      "  -1.85201998e+09  3.03062661e+09 -2.64370739e+09 -1.31357905e+09\n",
      "  -1.77625913e+09  2.56794654e+09  2.14627717e+09  2.82320425e+09]] \n",
      "updated weights:  [[-6.12329349e+09 -2.62443779e+09  1.48483064e+09 -5.82903630e+09\n",
      "  -1.19057344e+09  2.33018059e+09 -2.25441974e+09  2.16175772e+09\n",
      "  -5.90479715e+09 -1.02215056e+09  1.40906978e+09 -5.36635622e+09\n",
      "  -5.82903630e+09 -1.48483064e+09  6.19905434e+09  6.87598142e+09]]\n",
      "old bias: \n",
      " [[5.8290363e+09]] \n",
      "updated bias:  [[5.8290363e+09]]\n",
      "Actual output, iter: 34, input_vector:  4\n",
      " [[-4.46738245e+09]]\n",
      "old weights: \n",
      " [[-6.12329349e+09 -2.62443779e+09  1.48483064e+09 -5.82903630e+09\n",
      "  -1.19057344e+09  2.33018059e+09 -2.25441974e+09  2.16175772e+09\n",
      "  -5.90479715e+09 -1.02215056e+09  1.40906978e+09 -5.36635622e+09\n",
      "  -5.82903630e+09 -1.48483064e+09  6.19905434e+09  6.87598142e+09]] \n",
      "updated weights:  [[-8.80372296e+09  5.59916806e+07 -1.19559883e+09 -8.50946577e+09\n",
      "   1.48985603e+09 -3.50248876e+08 -4.93484921e+09 -5.18671754e+08\n",
      "  -3.22436768e+09  1.65827891e+09  4.08949925e+09 -8.04678569e+09\n",
      "  -8.50946577e+09  1.19559883e+09  3.51862487e+09  4.19555195e+09]]\n",
      "old bias: \n",
      " [[8.50946577e+09]] \n",
      "updated bias:  [[8.50946577e+09]]\n",
      "Actual output, iter: 35, input_vector:  5\n",
      " [[2.72373143e+10]]\n",
      "old weights: \n",
      " [[-8.80372296e+09  5.59916806e+07 -1.19559883e+09 -8.50946577e+09\n",
      "   1.48985603e+09 -3.50248876e+08 -4.93484921e+09 -5.18671754e+08\n",
      "  -3.22436768e+09  1.65827891e+09  4.08949925e+09 -8.04678569e+09\n",
      "  -8.50946577e+09  1.19559883e+09  3.51862487e+09  4.19555195e+09]] \n",
      "updated weights:  [[ 7.53866560e+09  1.63983802e+10 -1.75379874e+10  7.83292279e+09\n",
      "   1.78322446e+10 -1.66926374e+10  1.14075393e+10  1.58237168e+10\n",
      "   1.31180209e+10 -1.46841097e+10 -1.22528893e+10 -2.43891743e+10\n",
      "   7.83292279e+09  1.75379874e+10 -1.28237637e+10  2.05379405e+10]]\n",
      "old bias: \n",
      " [[-7.83292279e+09]] \n",
      "updated bias:  [[-7.83292279e+09]]\n",
      "Actual output, iter: 36, input_vector:  0\n",
      " [[-1.72832069e+10]]\n",
      "old weights: \n",
      " [[ 7.53866560e+09  1.63983802e+10 -1.75379874e+10  7.83292279e+09\n",
      "   1.78322446e+10 -1.66926374e+10  1.14075393e+10  1.58237168e+10\n",
      "   1.31180209e+10 -1.46841097e+10 -1.22528893e+10 -2.43891743e+10\n",
      "   7.83292279e+09  1.75379874e+10 -1.28237637e+10  2.05379405e+10]] \n",
      "updated weights:  [[ 1.79085898e+10  2.67683044e+10 -2.79079116e+10 -2.53700137e+09\n",
      "   7.46232042e+09 -6.32271327e+09  1.03761518e+09  5.45379264e+09\n",
      "   2.74809672e+09 -4.31418549e+09 -2.26228135e+10 -3.47590984e+10\n",
      "  -2.53700137e+09  2.79079116e+10 -2.31936879e+10  1.01680163e+10]]\n",
      "old bias: \n",
      " [[2.53700137e+09]] \n",
      "updated bias:  [[2.53700137e+09]]\n",
      "Actual output, iter: 37, input_vector:  1\n",
      " [[-6.70972208e+10]]\n",
      "old weights: \n",
      " [[ 1.79085898e+10  2.67683044e+10 -2.79079116e+10 -2.53700137e+09\n",
      "   7.46232042e+09 -6.32271327e+09  1.03761518e+09  5.45379264e+09\n",
      "   2.74809672e+09 -4.31418549e+09 -2.26228135e+10 -3.47590984e+10\n",
      "  -2.53700137e+09  2.79079116e+10 -2.31936879e+10  1.01680163e+10]] \n",
      "updated weights:  [[-2.23497427e+10  6.70266369e+10  1.23504209e+10 -4.27953339e+10\n",
      "  -3.27960121e+10 -4.65810458e+10  4.12959477e+10 -3.48045399e+10\n",
      "  -3.75102358e+10 -4.45725180e+10  1.76355190e+10 -7.50174309e+10\n",
      "  -4.27953339e+10 -1.23504209e+10  1.70646446e+10 -3.00903162e+10]]\n",
      "old bias: \n",
      " [[4.27953339e+10]] \n",
      "updated bias:  [[4.27953339e+10]]\n",
      "Actual output, iter: 38, input_vector:  2\n",
      " [[2.77445685e+11]]\n",
      "old weights: \n",
      " [[-2.23497427e+10  6.70266369e+10  1.23504209e+10 -4.27953339e+10\n",
      "  -3.27960121e+10 -4.65810458e+10  4.12959477e+10 -3.48045399e+10\n",
      "  -3.75102358e+10 -4.45725180e+10  1.76355190e+10 -7.50174309e+10\n",
      "  -4.27953339e+10 -1.23504209e+10  1.70646446e+10 -3.00903162e+10]] \n",
      "updated weights:  [[ 1.44117668e+11 -9.94407740e+10  1.78817832e+11  1.23672077e+11\n",
      "  -1.99263423e+11  1.19886365e+11 -1.25171463e+11  1.31662871e+11\n",
      "   1.28957175e+11 -2.11039929e+11  1.84102930e+11  9.14499800e+10\n",
      "   1.23672077e+11 -1.78817832e+11 -1.49402766e+11 -1.96557727e+11]]\n",
      "old bias: \n",
      " [[-1.23672077e+11]] \n",
      "updated bias:  [[-1.23672077e+11]]\n",
      "Actual output, iter: 39, input_vector:  3\n",
      " [[4.70373948e+11]]\n",
      "old weights: \n",
      " [[ 1.44117668e+11 -9.94407740e+10  1.78817832e+11  1.23672077e+11\n",
      "  -1.99263423e+11  1.19886365e+11 -1.25171463e+11  1.31662871e+11\n",
      "   1.28957175e+11 -2.11039929e+11  1.84102930e+11  9.14499800e+10\n",
      "   1.23672077e+11 -1.78817832e+11 -1.49402766e+11 -1.96557727e+11]] \n",
      "updated weights:  [[ 4.26342037e+11  1.82783595e+11 -1.03406537e+11  4.05896446e+11\n",
      "   8.29609460e+10 -1.62338004e+11  1.57052906e+11 -1.50561498e+11\n",
      "   4.11181544e+11  7.11844401e+10 -9.81214390e+10  3.73674349e+11\n",
      "   4.05896446e+11  1.03406537e+11 -4.31627135e+11 -4.78782096e+11]]\n",
      "old bias: \n",
      " [[-4.05896446e+11]] \n",
      "updated bias:  [[-4.05896446e+11]]\n",
      "\n",
      "\n",
      "Finished\n",
      "Updated last weight\n",
      " [[ 4.26342037e+11  1.82783595e+11 -1.03406537e+11  4.05896446e+11\n",
      "   8.29609460e+10 -1.62338004e+11  1.57052906e+11 -1.50561498e+11\n",
      "   4.11181544e+11  7.11844401e+10 -9.81214390e+10  3.73674349e+11\n",
      "   4.05896446e+11  1.03406537e+11 -4.31627135e+11 -4.78782096e+11]]\n",
      "Updated last bias\n",
      " [[-4.05896446e+11]]\n"
     ]
    }
   ],
   "source": [
    "one = np.matrix('1 1 -1 -1 -1 1 -1 -1, -1 1 -1 -1 -1 1 -1 -1').T\n",
    "one_shifted = np.matrix('-1 1 1 -1 -1 -1 1 -1 -1 -1 1 -1 -1 -1 1 -1').T\n",
    "\n",
    "two = np.matrix('-1 1 -1 -1 1 -1 1 -1 -1 1 -1 -1 -1 1 1 1').T\n",
    "two_shifted = np.matrix('-1 -1 1 -1 -1 1 -1 1 -1 -1 1 -1 -1 -1 1 1').T\n",
    "\n",
    "four = np.matrix('-1 1 -1 -1 1 -1 -1 -1 1 1 1 -1 -1 1 -1 -1').T\n",
    "four_shifted = np.matrix('-1 -1 1 -1 -1 1 -1 -1 -1 1 1 1 -1 -1 1 -1').T\n",
    "\n",
    "input_vectors = np.concatenate((one, one_shifted, two, two_shifted, four, four_shifted), axis = -1)\n",
    "\n",
    "targets = np.array([1, 1, 2, 2, 4, 4])\n",
    "## initialize weight and biases as zero\n",
    "weights = np.matrix('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')\n",
    "bias = 1\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "new_bias, new_weights, error = ADALINE_learning(input_vectors, \n",
    "                                        targets,\n",
    "                                        learning_rate,\n",
    "                                        weights, \n",
    "                                        bias, \n",
    "                                        verbose=True,\n",
    "                                        epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc30dbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAERCAYAAABy/XBZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAidklEQVR4nO3deZxU1Z338c+vqpdqmq5GEGgEWUQUocFmVdyVaBhhBBTHZIjBJS554pNk4hOVmKiJk4kZ82Q3C4kjbqNEEl4yxnlE44YZURaBABJxYZUdm6Ybml7q9/xR1W03NNANXXWrqO/79Wq77lLn/u7Frl+dc+49x9wdERHJPqGgAxARkWAoAYiIZCklABGRLKUEICKSpZQARESylBKAiEiWyrgEYGb/YWbbzGxFK/a9wMyWmFmdmU05YNv/M7NyM3suedGKiKSvjEsAwExgXCv3XQ9cB/xnC9seBK5tn5BERDJPxiUAd38d2NV0nZn1T3yjX2xm881sYGLfte6+HIi1UM5fgD0pCVpEJA3lBB1AO5kB3Orua8zsLOBXwCUBxyQiktYyPgGYWUfgHOAZM2tYnR9cRCIimSHjEwDxZqxydy8LOhARkUyScX0AB3L3CuAjM7sawOLODDgsEZG0Z5k2GqiZPQVcBJwIbAXuBV4Gfg30AHKBp939e2Y2CpgDnABUA1vcfXCinPnAQKAjsBO40d1fSO3ZiIgEJ+MSgIiItI+MbwISEZGjk1GdwCeeeKL37ds36DBERDLK4sWLd7h71wPXZ1QC6Nu3L4sWLQo6DBGRjGJm61paryYgEZEspQQgIpKllABERLKUEoCISJZSAhARyVJKACIiWUoJQEQkSykBiIgcI3fn2aWb2L5nf9ChtIkSgIjIMVq6oZyvPb2UPy7ZGHQobaIEICJyjB5/M/6gbfne2oAjaRslABGRY7Crqobnlm8GYE+1EoCISNb4w6IN1NTH6JAXpqK6Luhw2iSjBoMTEUkn9THniQXrOKtfZ/bV1qsGICKSLV57bxsbP9nHF8f0pSiSw54MqwEoAYiIHKXH31xH16J8LhvcnWgkl4p9qgGIiBz31u/cy6vvbefzo3uTGw6pBiAiki2efGsdITP+eXRvAKKRXPUBiIgc76pr65m1aAOXDepOSXEEgKJILlU19dTVxwKOrvWUAERE2ujPyzdTvreWa8/u07iuKBK/qbJyf+Y0AykBiIi00WML1tG/ayFj+ndpXBctyAWgYp8SgIjIcWn5xnKWbSjn2rP7YGaN6xtqABUZ1A+gBCAi0gZPLFhHh7wwV47o1Wx9QwLIpDuBlABERFqpfG8Nzy79mEnDehKN5Dbb1rCsGoCIyHFo9uKN7K+LNev8bdCQAFQDEBE5zsQS4/6M6nsCZ/SIHrQ9WtDQBKQagIjIcWX++ztYu3MvX2jh2z9Ax/xEJ7DuAjq+lJeX86tf/apx+dVXX2XChAkBRpQcTc9r7ty5PPDAA+1S7uWXX055eXmr9p05cyYff/xx43Lfvn3ZsWNHu8Qhciwe/Z+1nNgxj3GlJS1uzwmH6JAXVg3geHNgAkiFurpgv0VcccUV3HXXXe1S1vPPP0+nTp1ate+BCSAo9fX1SSurtWW3ZwxybP6+ZQ8vr97GF8f0JT8nfMj9opFcdQIfb+666y4++OADysrK+OY3vwlAZWUlU6ZMYeDAgUydOhV3B2Dx4sVceOGFjBgxgs9+9rNs3rz5oPLWrl3LJZdcwtChQxk7dizr168H4LrrruPWW2/lrLPO4o477uDtt99mzJgxDBs2jHPOOYe///3vQPxD8sorr2TcuHEMGDCAO+64o7Hshx9+mNNOO43Ro0dz0003cdtttwGwfft2rrrqKkaNGsWoUaP461//ethznjlzZuN7r7vuOr761a9yzjnncMoppzB79uzG/R588EFGjRrF0KFDuffee1ssq+FbfFVVFePHj+fMM8+ktLSUWbNmNdtv9uzZLFq0iKlTp1JWVsa+ffsA+MUvfsHw4cMZMmQIq1evBqCqqoobbriB0aNHM2zYMJ599tmDjnvPPfdQVlZGWVkZPXv25PrrrwfgiSeeYPTo0ZSVlXHLLbc0ftB27NiR22+/nTPPPJM333yTH//4x5SWllJaWspPf/rTFs9t3rx5jBkzhuHDh3P11VdTWVnZeM533nknw4cP55lnnjlo+amnnmLIkCGUlpZy5513NpZ3YAySHn772gd0yAvzxTEtN/80yLgB4dw9Y35GjBjhQfjoo4988ODBjcuvvPKKR6NR37Bhg9fX1/vZZ5/t8+fP95qaGh8zZoxv27bN3d2ffvppv/766w8qb8KECT5z5kx3d3/44Yd94sSJ7u4+bdo0Hz9+vNfV1bm7++7du722ttbd3V988UW/8sor3d39kUce8X79+nl5ebnv27fPe/fu7evXr/dNmzZ5nz59fOfOnV5TU+PnnXeef+UrX3F3989//vM+f/58d3dft26dDxw48KC4XnnlFR8/fnzjMRreO23aNJ8yZYrX19f7ypUrvX///u7u/sILL/hNN93ksVjM6+vrffz48f7aa68dVG6fPn18+/btPnv2bP/Sl77UuL68vPygfS+88EJfuHBhs/f+/Oc/d3f3hx56yG+88UZ3d58+fbo//vjj7u7+ySef+IABA7yysvKg8hq2l5aW+qJFi3zVqlU+YcIEr6mpcXf3L3/5y/7oo4+6uzvgs2bNcnf3RYsWeWlpqVdWVvqePXt80KBBvmTJkmblbt++3c8///zG4z7wwAP+3e9+tzHuH/7wh83Oo2F506ZNfvLJJ/u2bdu8trbWL774Yp8zZ85BMUjrxWIx376n2het3eUvr97qKzft9l2V+z0Wix1z2Rs/2ev9p//Zvzt35RH3nfzQGz71dwuO+ZjtDVjkLXymBjojmJmNA34GhIHfu3v7NDqnwOjRo+nVK/4gSFlZGWvXrqVTp06sWLGCSy+9FIhX4Xv06HHQe998803+9Kc/AXDttdc2+wZ/9dVXEw7Hq5i7d+9m2rRprFmzBjOjtvbTquXYsWMpLi4GYNCgQaxbt44dO3Zw4YUX0rlz58ay3nvvPQBeeuklVq1a1fj+iooKKisr6dixY6vOd9KkSYRCIQYNGsTWrVuB+LffefPmMWzYMCBeK1qzZg0XXHBBi2UMGTKE22+/nTvvvJMJEyZw/vnnt+rYV155JQAjRoxovG7z5s1j7ty5/OhHPwKgurqa9evXc8YZZzR7r7vzhS98gW984xuMGDGCX/7ylyxevJhRo0YBsG/fPrp16wZAOBzmqquuAuCNN95g8uTJFBYWNsYwf/78xnMFWLBgAatWreLcc88FoKamhjFjxjRuv+aaa5rF0rC8cOFCLrroIrp27QrA1KlTef3115k0aVKzGORge6prWbqhnI92VLF+517W7drLhl17Wb9rL3trDm4yi+SG6FFcQEk0Qo/iCCXFEa4a0Yv+XVv3/z3A7+d/CMCXzu93xH2jBbnsqqpp/QkFLLAEYGZh4CHgUmAjsNDM5rr7qsO/Mz3k5+c3vg6Hw9TV1eHuDB48+Jiq7g0fOADf+c53uPjii5kzZw5r167loosuOuzxDycWi7FgwQIikchRxdX0eJ5o7nJ3pk+fzi233NKqMk477TSWLFnC888/z7e//W3Gjh3LPffc0+pjNz1Pd+ePf/wjp59++mHfe99999GrV6/G5h93Z9q0afzgBz84aN9IJNKYfFvD3bn00kt56qmnWtze9N+ypeWWtDWG492Oyv0s/GgXb6/dxcK1u1j1cQWx+P9+5OeE6N25A326dGBM/y6Nr4sLctlWsZ+Pd1ezZfc+Nu+uZvPuat76aBdbKqp5dunHzPuXCyjMP/LH3ydVNTz99gauKDuJkzoVHHH/okgu63buPdbTTpkgawCjgffd/UMAM3samAi0ewJYOuNWbOvfjvr95Xtr2bVxDcvuj3/Te/+j3VSs+bhxecfCD1n/8QuUfnQim95bymM3DeXM3kXU1sdYt7OaU7t1aFZe6Ykx/v1zg5hQ1o1n39nG0G7OsvvPZdeyNaytfpNl7/4EgPVvr2ZI9QKW7Z7Fr19eT83u7Sy7/1zWv7ONHZsqWXb/OwBUrHmX9x+7jd5dIrw4dwXzv7WaDnlhHpu5klO7d2DZ/e8w6iRj+sSBXHdeTwBWb65iYI/mH0hNz6vpMQ6MK1a7j2X3n8upO8r55awZDN3wCB3yw2yt2E9uyOjcMa9ZuTW7t7DiR5dTW+8UF+QwJDfElJN38aenfsZEe6HZvr75XZY+dB25pxQ3e+8Jhbm8t6mSynVrWXb/uZQVbuXeL17EXeP7YWas3lzJwB7Nv9W9tnoXz87fxO+vH9z4b9Vz214e/M/VXBZ7ic4d89i9t5aqmnpO6hRpPC+A7h9X8tCc97nc5wHw1IzlfP+qASy7/9N+i45Vtbz638v4r68Pp3eXAvbV1LOtooY+JxY0i/vA8yjcU8NLc5fz6l2riRbk8LvHVvG5s3qw7P63msWQLHbQixa2HbTRm/y3yVqHmDvu8W2eeB3DMYyQgVn8d8iaLjdZF2q6Pf66pj5GRXUd1bX1nAD8g8HV+bkUdc2hKJJDh7wccsOGYRADdiR+DiUS/6kormXV5gq2/yJCYZcjJ+SqT/byiO1jaHkxPHLkj8t/2VHJJ1U18EjnI+7bZiVD4B/at5EkyATQE9jQZHkjcNaBO5nZzcDNAL179z6qAxXkhbHco/9WVVAcZkTfYq5+aCnnn3YCFw3sTNiMgkSZOSEjLxwiWpDLL6aewb/+1wfsqa6nPuZMO/ckhvQsalbevRNPZfrs93jsfz6mc2EuP5hyGgW54cZyGsq95cKTueuZ93j49Y1cOLAzIaAgN0xeOERO6NPjh83IzwnRt0sHvnzxyVw7YznFBbmc0rWAEzrkUpAb5t6Jp/K9Z9/nn361lPqYM7JvMd+bPKBZXPk5ocbzanqMA+OyRBxjz+jCxl3VXPf7eHLtkBfmwWtOb9yvQQiI5Ib5YFsl//7fHxIyIydk3Dfp1IP2nTKqhO8/9yGR3BCzvnxm43sLcsPN4vvapX34t+c+5JpfLSPm0OuECL+9bnCzsp5csJkde2q49nfx+C45ozNfu7Qv3/hsX/7X4+8Scyc3FOKeif0p6BpuPC+A4X2KuWpEd76YeO8/jerBsN7Fzcrv2SnMA1efzrdmr6EmMQb81y/ty8AeHZvF3fQaFOSG6d25gP8zrh+3zFyJAxee3pnLh3Ztdm0P0sKHdZt4s18tbvSWNx4UgDXJIGbxLSFLvDbDmuwT8/gDVO5OjIbX8aRRG4OYx4i5x/dzj28HwiGjKD+HbkX5FEVyKMzLIWTHehHid+l0j0bYUlFNl8I8ig4YzqGpene2VFTTqSCXDrmt+6jMCYWoix32QqYV88P/qyfvwGZTgHHu/qXE8rXAWe5+26HeM3LkSF+0aFGqQsxIDe36dXV1TJ48mRtuuIHJkycHHZZIq8Vi3phMkqFqfx2X/eR18nNDPP/V84kc4svho/+zlnvnruSZW8cwqm/rvtE/9Mr7PPjC31l9/7hDlhsEM1vs7iMPXB/kbaCbgJObLPdKrJNjcN9991FWVkZpaSn9+vVj0qRJQYck0iahkCXtwx+gMD+HB64awofbq/jZX9a0uE9dfYzfzf+QEX1OaPWHPzSZEyBDngUIsgloITDAzPoR/+D/HPDPAcZzXGi4K0ZEDu38AV35p5G9mPH6h4wf0oPSns2b9/78t81s/GQf9/7j4EOU0LJokyGhuxUdYec0EFgNwN3rgNuAF4B3gT+4+8qg4hGR7HL3+EF0Kczjm7OXU9tkHl9359evfsCAbh0ZO7Bbm8rMtDkBAn0S2N2fd/fT3L2/u38/yFhEJLsUF+Tyr5NKeXdzBb959YPG9a++t53VW/Zw8wWnEAq1rSmqcU6AfZnRBKShIEQka102uIQJQ3vwi5ffZ83WPQD85tUPKIlGmFjWs83lFWXYnABKACKS1b57xWAK88N8c/ZyFq/bxVsf7eLG8/qRl9P2j8dPm4BUAxARSXtdOuZz3xWDWbqhnJsfW0w0ksPnzzq6Z44y7S4gJQARyXpXnHkSYwd2Y2dVDdeO6dM4uUtbFeaFCVnmNAEFOhiciEg6MDN+cOUQfv/GR9x0/inHVE5RJDdjOoGVAEREgG7RCN+6/Iwj73gEmTQngJqARETaUVEklwolABGR7BON5KgTWEQkGxVFctUEJCKSjaKRHD0HICKSjaIFmXMXkBKAiEg7KorkULm/jlgGTAyjBCAi0o6KIjnEHKpq0r8fQAlARKQdRTNoQDglABGRdpRJI4IqAYiItKNoQXyAhUx4FkAJQESkHX1aA1ACEBHJKpk0LaQSgIhIO8qkaSGVAERE2lFDDSATBoRTAhARaUeR3DB54ZA6gUVEslG0IDPmBFACEBFpZ5kyIqgSgIhIO4tGctQJLCKSjeI1ACUAEZGskynzAisBiIi0s2gkV3cBiYhkI9UADsPMrjazlWYWM7ORQcQgIpIsRZFc9tbUU1sfCzqUwwqqBrACuBJ4PaDji4gkTcOIoJVpXgvICeKg7v4ugJkFcXgRkaRqOifACYV5AUdzaGnfB2BmN5vZIjNbtH379qDDERE5ok/HA0rvjuCk1QDM7CWgpIVNd7v7s60tx91nADMARo4cmf6zLItI1mscETRbE4C7fyZZZYuIpLNMmRMg7ZuAREQyTXFBZswJENRtoJPNbCMwBvizmb0QRBwiIsmQKTWAoO4CmgPMCeLYIiLJ1jE/MzqB1QQkItLOcsIhCvPCaV8DUAIQEUmCTBgRVAlARCQJiiI5VOxTDUBEJOtEC3LZs181ABGRrJMJI4IqAYiIJEE0kqvnAEREspFqACIiWaooMSuYe/oOYaYEICKSBNGCHGrrnf116TspjBKAiEgSFGXAiKBKACIiSRBtmBMgjZ8FUAIQEUmCaOOsYKoBiIhklUwYEVQJQEQkCaIF6gMQEclKqgGIiGSpxruA0vhpYCUAEZEkKMwLEzLVAEREso6Zpf2cAEoAIiJJUhTJoUI1ABGR7BNVDUBEJDtlfA3A4k5ORTAiIseTojSfE+CICcDjY5k+n4JYRESOK9GC9J4ToLVNQEvMbFRSIxEROc5EE3MCpKucVu53FjDVzNYBVYARrxwMTVpkIiIZLhrJoXJ/HbGYEwpZ0OEcpLUJ4LNJjUJE5DhUFMnFHapq6hqfDE4nrWoCcvd1QCfgHxM/nRLrRETkEBrGA0rXO4FalQDM7GvAk0C3xM8TZva/j/agZvagma02s+VmNsfMOh1tWSIi6aphRNB0fRagtZ3ANwJnufs97n4PcDZw0zEc90WgNNGH8B4w/RjKEhFJS+k+ImhrE4AB9U2W6xPrjoq7z3P3hiuyAOh1tGWJiKSrdB8RtLWdwI8Ab5nZnMTyJODhdorhBmDWoTaa2c3AzQC9e/dup0OKiCRfNM1rAEdMAGYWIv4t/VXgvMTq6939nSO87yWgpIVNd7v7s4l97gbqiPcvtMjdZwAzAEaOHOlHildEJF001gDStA/giAnA3WNm9pC7DwOWtLZgd//M4bab2XXABGBs4mljEZHjyvHSB/AXM7vKzNrlSQYzGwfcAVzh7nvbo0wRkXQTyQ2TlxNK2xpAaxPALcAzwH4zqzCzPWZWcQzH/SVQBLxoZkvN7DfHUJaISNqKRnKo2JeeNYDW9gGMc/e/ttdB3f3U9ipLRCSdpfOcAK0ZDTRG/Bu7iIi0UVEkfUcEDaQPQEQkWxSl8YigbekD+APt1wcgIpIV0nlOgNY+CFYMTAX6ufv3zKw30CN5YYmIHB+K8tN3VrDW1gAeIj7+z+cTy3tQv4CIyBEdD30AZ7n7V4BqAHf/BMhLWlQiIseJaEEu+2rrqa2PBR3KQVqbAGrNLAw4gJl1BdLvbERE0kw6Pw3c2gTwc2AO0M3Mvg+8Afxb0qISETlORCPpOydAqzqB3f1JM1sMjCU+DPQkd383qZGJiBwH0rkG0Nq7gHD31cDqJMYiInLcSec5AVrbBCQiIkchWpC+8wIrAYiIJFE0jecEUAIQEUmidO4DUAIQEUmijvkNCUA1ABGRrJITDlGYF07LOQGUAEREkixakJ5zAigBiIgkWbqOB6QEICKSZOk6J4ASgIhIkkVVAxARyU6qAYiIZCn1AYiIZKmGu4DcPehQmlECEBFJsqJIDrX1TnVtek2jogQgIpJkXQrjEyjuqNwfcCTNKQGIiCRZSXEBAFsqqgOOpDklABGRJCuJRgDYslsJQEQkq5QUKwGIiGSlaCSHgtywmoAAzOx+M1tuZkvNbJ6ZnRREHCIiqWBm9CiOqAaQ8KC7D3X3MuA54J6A4hARSYnu0YhqAADuXtFksRBIr6cjRETaWUka1gBygjqwmX0f+CKwG7j4MPvdDNwM0Lt379QEJyLSzkqKI2ytqCYWc0IhCzocIIk1ADN7ycxWtPAzEcDd73b3k4EngdsOVY67z3D3ke4+smvXrskKV0QkqUqiEepizs6qmqBDaZS0GoC7f6aVuz4JPA/cm6xYRESC1vRW0K5F+QFHExfUXUADmixOBFYHEYeISKo0PgyWRh3BQfUBPGBmpwMxYB1wa0BxiIikRI/GGsC+gCP5VCAJwN2vCuK4IiJB6dIxn3DI0qoGoCeBRURSIBwyuhflszmNbgVVAhARSZHuiVtB04USgIhIivQojqgGICKSjbpHI2xVAhARyT4l0QhVNfXsqa4NOhRACUBEJGXSbV4AJQARkRRJt4fBlABERFKkR2Ju4HTpCFYCEBFJkW7R+BhA6dIRrAQgIpIikdwwnQvz2KwmIBGR7JNOt4IqAYiIpFA6PQymBCAikkLdo+kzHIQSgIhICvUojrCzqob9dfVBh6IEICKSSg3PAmyr2B9wJEoAIiIp1b04fR4GUwIQEUmhhpnB0qEjWAlARCSFuieagNLhVlAlABGRFIpGcuiQF1YNQEQk25gZJWlyK6gSgIhIipUUR9i8e1/QYSgBiIikWrwGoNtARUSyTklicvhYzAONQwlARCTFSooj1MWcHVXB1gKUAEREUqxxZrCA7wRSAhARSbF0mRtYCUBEJMUaagBB3wqqBCAikmJdOuaTE7LAHwYLNAGY2e1m5mZ2YpBxiIikUjhkdCvKD3xAuMASgJmdDFwGrA8qBhGRoJQUR7K6D+AnwB1AsDfCiogEoKQ4kp01ADObCGxy92Wt2PdmM1tkZou2b9+eguhERJKvJFrAlt3VuAf3HTgnWQWb2UtASQub7ga+Rbz554jcfQYwA2DkyJGqLYjIcaGkOJ+9NfXs2V9HNJIbSAxJSwDu/pmW1pvZEKAfsMzMAHoBS8xstLtvSVY8IiLppKS4AIg/CxBUAkh5E5C7/83du7l7X3fvC2wEhuvDX0SySTo8DaznAEREAtAjDZ4GTloTUGslagEiIlmlWzQfCHZyeNUAREQCkJ8TpnNhnhKAiEg2KokG+zCYEoCISECCfhpYCUBEJCBBPw2sBCAiEpCSaIRdVTVU19YHcnwlABGRgDRMDLMtoAnilQBERALS+DBYQM1ASgAiIgFpeBhs8+59gRxfCUBEJCDdi4OdGlIJQEQkIEX5ORTmhQObGlIJQEQkIGZG9+KIagAiItkoyKeBlQBERAIU5NPASgAiIgEqiUbYtmc/9bHUT3ioBCAiEqAexRHqYs7OytQ/DKYEICISoO4BPgymBCAiEqAeibmBg7gVVAlARCRA3YvjM4MFcSuoEoCISIBOLMwnJ2SqAYiIZJtQyOgejbA1gAQQ+KTwIiLZblxpSePIoKmkBCAiErDvTBgUyHHVBCQikqWUAEREspQSgIhIllICEBHJUkoAIiJZSglARCRLKQGIiGQpJQARkSxl7qmfhOBomdl2YN1Rvv1EYEc7htNeFFfbKK62UVxtk65xwbHF1sfdux64MqMSwLEws0XuPjLoOA6kuNpGcbWN4mqbdI0LkhObmoBERLKUEoCISJbKpgQwI+gADkFxtY3iahvF1TbpGhckIbas6QMQEZHmsqkGICIiTSgBiIhkqaxIAGY2zsz+bmbvm9ldQcfTwMzWmtnfzGypmS0KMI7/MLNtZraiybrOZvaima1J/D4hTeK6z8w2Ja7ZUjO7PIC4TjazV8xslZmtNLOvJdYHes0OE1eg18zMImb2tpktS8T13cT6fmb2VuLvcpaZ5aVJXDPN7KMm16sslXE1iS9sZu+Y2XOJ5fa/Xu5+XP8AYeAD4BQgD1gGDAo6rkRsa4ET0yCOC4DhwIom6/4duCvx+i7gh2kS133A/wn4evUAhideFwHvAYOCvmaHiSvQawYY0DHxOhd4Czgb+APwucT63wBfTpO4ZgJTgvx/LBHTN4D/BJ5LLLf79cqGGsBo4H13/9Dda4CngYkBx5RW3P11YNcBqycCjyZePwpMSmVMcMi4Aufum919SeL1HuBdoCcBX7PDxBUoj6tMLOYmfhy4BJidWB/E9TpUXIEzs17AeOD3iWUjCdcrGxJAT2BDk+WNpMEfRYID88xssZndHHQwB+ju7psTr7cA3YMM5gC3mdnyRBNRypummjKzvsAw4t8e0+aaHRAXBHzNEs0ZS4FtwIvEa+Xl7l6X2CWQv8sD43L3huv1/cT1+omZ5ac6LuCnwB1ALLHchSRcr2xIAOnsPHcfDvwD8BUzuyDogFri8TpnWnwzAn4N9AfKgM3A/w0qEDPrCPwR+Lq7VzTdFuQ1ayGuwK+Zu9e7exnQi3itfGCqY2jJgXGZWSkwnXh8o4DOwJ2pjMnMJgDb3H1xso+VDQlgE3Byk+VeiXWBc/dNid/bgDnE/zDSxVYz6wGQ+L0t4HgAcPetiT/aGPA7ArpmZpZL/EP2SXf/U2J14NespbjS5ZolYikHXgHGAJ3MLCexKdC/yyZxjUs0pbm77wceIfXX61zgCjNbS7zJ+hLgZyThemVDAlgIDEj0oOcBnwPmBhwTZlZoZkUNr4HLgBWHf1dKzQWmJV5PA54NMJZGDR+wCZMJ4Jol2mMfBt519x832RToNTtUXEFfMzPramadEq8LgEuJ90+8AkxJ7BbE9WoprtVNkrgRb2dP6fVy9+nu3svd+xL/vHrZ3aeSjOsVdE93Kn6Ay4nfEfEBcHfQ8SRiOoX4HUnLgJVBxgU8RbxpoJZ42+KNxNsc/wKsAV4COqdJXI8DfwOWE//A7RFAXOcRb95ZDixN/Fwe9DU7TFyBXjNgKPBO4vgrgHsS608B3gbeB54B8tMkrpcT12sF8ASJO4WC+AEu4tO7gNr9emkoCBGRLJUNTUAiItICJQARkSylBCAikqWUAEREspQSgIhIllICEEkRM7uoYWRHkXSgBCAikqWUAEQOYGZfSIwTv9TMfpsYMKwyMTDYSjP7i5l1TexbZmYLEgOHzWkYaM3MTjWzlxJjzS8xs/6J4jua2WwzW21mTyaeNhUJhBKASBNmdgZwDXCuxwcJqwemAoXAIncfDLwG3Jt4y2PAne4+lPjTow3rnwQecvczgXOIP9EM8RE6v058nP5TiI/7IhKInCPvIpJVxgIjgIWJL+cFxAd1iwGzEvs8AfzJzIqBTu7+WmL9o8AziTGeerr7HAB3rwZIlPe2u29MLC8F+gJvJP2sRFqgBCDSnAGPuvv0ZivNvnPAfkc7hsr+Jq/r0d+gBEhNQCLN/QWYYmbdoHGe3z7E/1YaRmL8Z+ANd98NfGJm5yfWXwu85vHZuDaa2aREGflm1iGVJyHSGvr2IdKEu68ys28Tn6ktRHwk0q8AVcQnDPk28SahaxJvmQb8JvEB/yFwfWL9tcBvzex7iTKuTuFpiLSKRgMVaQUzq3T3jkHHIdKe1AQkIpKlVAMQEclSqgGIiGQpJQARkSylBCAikqWUAEREspQSgIhIlvr/PYqV3lry0hoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(error, 2, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
